<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>clustRviz Details • clustRviz</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="clustRviz Details">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">clustRviz</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/QuickStart.html">clustRviz Quick Start</a>
    </li>
    <li>
      <a href="../articles/clusRvizDetails.html">clustRviz Details</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>clustRviz Details</h1>
                        <h4 class="author">John Nagorski</h4>
            
            <h4 class="date">2018-08-24</h4>
      
      
      <div class="hidden name"><code>clusRvizDetails.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>The <code>clustRviz</code> package intends to make fitting and visualizing CARP and CBASS solution paths an easy process. In the <a href="Getting_Started.html">Getting Started</a> vignettee we provide a quick start guide for basic usage, fitting, and plotting. In this vignette, we build on the basics and provide a more detailed explanation for the variety of options available in <code>clustRviz</code>.</p>
</div>
<div id="background" class="section level1">
<h1 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h1>
<p>The starting point for CARP is the Convex Clustering <span class="citation">(Hocking et al. 2011; Chi and Lange 2015; Tan and Witten 2015)</span> problem :</p>
<p><span class="math display">\[
\underset{{\boldsymbol{U}}}{\textrm{minimize}} \;\;
\frac{1}{2} \| {\boldsymbol{X}} - {\boldsymbol{U}} \|_F^2 + 
\lambda \sum_{ l &lt; m} 
w_{l,m} \| {\boldsymbol{u}}_l - {\boldsymbol{u}}_m \|_2
\]</span></p>
<p>where <span class="math inline">\({\boldsymbol{X}}\)</span> is an <span class="math inline">\(p \times n\)</span> input data matrix, consisting of <span class="math inline">\(p\)</span> measurements on <span class="math inline">\(n\)</span> subjects, <span class="math inline">\(\lambda &gt; 0\)</span> a regularization parameter, and <span class="math inline">\(w_{l,m}&gt;0\)</span> a weight for each pair of observations; here <span class="math inline">\(\| . \|_F\)</span> and <span class="math inline">\(\| . \|_2\)</span> denote the Frobenius norm and <span class="math inline">\(l_2\)</span> norm, respectively.</p>
<p>Briefly, Convex Clustering seeks to find and estimate,<span class="math inline">\(\hat{{\boldsymbol{U}}} \in \mathbb{R}^{p\times n}\)</span>, such that it is faithful to the original data (Frobenius norm loss term) while also encouraging fusions among observations (<span class="math inline">\(l_2\)</span> regularization between columns of <span class="math inline">\({\boldsymbol{U}}\)</span>, denoted <span class="math inline">\(u_l\)</span>). At small values of regularization, <span class="math inline">\(\lambda \approx 0\)</span>, Convex Clustering returns estimates similar to the original data with little or no fusion among observations. As regularization increases, more fusions occur and Convex Clustering returns estimates such that <span class="math inline">\(\| \hat{{\boldsymbol{u}}}_l - \hat{{\boldsymbol{u}}}_m \| = 0\)</span>. When such fusions occur we say that observations <span class="math inline">\(l\)</span> and <span class="math inline">\(m\)</span> belong to the same cluster. Taken to the extreme, sufficiently large values of <span class="math inline">\(\lambda\)</span> result in all observations belonging to the same cluster.</p>
<p>When fitting for multiple values of <span class="math inline">\(\lambda\)</span> Convex Clustering results in a continious solution path of clustering solutions. One solution method for the problem above is via the alternatving direction method of multipliers (ADMM) <span class="citation">(Boyd et al. 2011)</span>. For a given <span class="math inline">\(\lambda\)</span>, Convex Clustering can be solved by iteratively applying ADMM updates until convergence <span class="citation">(Chi and Lange 2015)</span>. However in order to obtain a full path of clustering solutions, this method must be employed for multiple <span class="math inline">\(\lambda_k\)</span> which is computationally expensive.</p>
<p>To address the computational burden of Convex Clustering, we utilize the framework of Algorithmic Regularization Paths <span class="citation">(Hu, Chi, and Allen 2016)</span> to develop efficient methods for approximating the Convex Clustering and Biclustering solution paths: Convex Clustering via Algorithmic Regularization Paths (CARP) and Convex Biclustering via Algorthmic Regularization with Small Steps (CBASS), respectively. Rather than fully solving the Convex Clustering optimization problem at each <span class="math inline">\(\lambda_k\)</span>, we instead perform single updates combined with gradual increases in regularization at each step. As regularization increases with each iteration, the column differences of the iterates, <span class="math inline">\(\| {\boldsymbol{u}}^{(k)}_l - {\boldsymbol{u}}^{(k)}_m \|\)</span>, eventally become <span class="math inline">\(0\)</span> for all <span class="math inline">\(l,m\)</span>. In contrast to traditional iterative solution techniques, we instead employ the iterates themselves as approximations for the true solution path. Remarkably, this approximation not only works well empirically, but can be shown theoretically to well approximate the true Convex Clustering solution path.</p>
</div>
<div id="preprocessing-and-inputs" class="section level1">
<h1 class="hasAnchor">
<a href="#preprocessing-and-inputs" class="anchor"></a>Preprocessing and Inputs</h1>
<p>While the <code>CARP</code> and <code>CBASS</code> functions provides several reasonable default choices for weights, algorithms, etc, it is important to know their details if one wishes to compute more customized clustering choices. Here we examine several of the inputs to <code>CARP</code> and <code>CBASS</code>, as well as their preprocessing technqiues</p>
<p>Here we use a dataset of presidential speechs obtained from <a href="http://www.presidency.ucsb.edu/index_docs.php">The American Presidency Project</a> to illustrate the use of <code>clustRviz</code>. The presidential speech data set contains the top 75 most variable log-transformed word counts of each US president, aggregated over several speeches. Additional text processing such as removing stop words and stemming have been done via the <code>tm</code> package.</p>
<p>Let’s begin by loading our package and the dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(clustRviz)
<span class="kw">data</span>(<span class="st">"presidential_speech"</span>)
Xdat &lt;-<span class="st"> </span>presidential_speech
obs.labels &lt;-<span class="st"> </span><span class="kw">rownames</span>(Xdat)
var.labels &lt;-<span class="st"> </span><span class="kw">colnames</span>(Xdat)
Xdat[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]
<span class="co">#&gt;                     amount appropri  british     cent commerci</span>
<span class="co">#&gt; Abraham Lincoln   3.433987 2.397895 1.791759 2.564949 2.708050</span>
<span class="co">#&gt; Andrew Jackson    4.248495 4.663439 2.995732 1.945910 3.828641</span>
<span class="co">#&gt; Andrew Johnson    4.025352 3.091042 2.833213 3.332205 2.772589</span>
<span class="co">#&gt; Barack Obama      1.386294 0.000000 0.000000 1.386294 0.000000</span>
<span class="co">#&gt; Benjamin Harrison 4.060443 4.174387 2.302585 4.304065 3.663562</span>
<span class="kw">head</span>(obs.labels)
<span class="co">#&gt; [1] "Abraham Lincoln"   "Andrew Jackson"    "Andrew Johnson"   </span>
<span class="co">#&gt; [4] "Barack Obama"      "Benjamin Harrison" "Calvin Coolidge"</span>
<span class="kw">head</span>(var.labels)
<span class="co">#&gt; [1] "amount"     "appropri"   "british"    "cent"       "commerci"  </span>
<span class="co">#&gt; [6] "commission"</span></code></pre></div>
<div id="preprocessing" class="section level2">
<h2 class="hasAnchor">
<a href="#preprocessing" class="anchor"></a>Preprocessing</h2>
<div id="normalization" class="section level3">
<h3 class="hasAnchor">
<a href="#normalization" class="anchor"></a>Normalization</h3>
<p>An important first choice before clustering is whether to center and scale our observations. Centering is typically appropriate, and is done by default for CARP and CBASS. The choice of scaling is left to the user discression, but should typically be applied if measurements are a vastly different scales. In the case of the presidental speech dataset, all variables are of the same type and so we do not scale our data matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Centering data before computing the CARP solution path</span>
Xdat.preprocessed &lt;-<span class="st"> </span><span class="kw">scale</span>(Xdat,<span class="dt">center=</span><span class="ot">TRUE</span>,<span class="dt">scale=</span><span class="ot">FALSE</span>)</code></pre></div>
<p>In the <code>CARP</code> function this preprocessing is done via the <code>X.center</code> and <code>X.scale</code> arguements. If the data is pre-processed outside of <code>CARP</code>, as is the case here, these options may be set to <code>FALSE</code>; by default, <code>CARP</code> with center but not scale an inputted data matrix.</p>
<p>Both <code>CARP</code> and <code>CBASS</code> (below) admit several options for computing the (bi)clustering solution path. While we will encounter many options along the way, see the <code>carp.control</code> and <code>cbass.control</code> functions for full details.</p>
<p>Similarly, the <code>CBASS</code> function also requires that data preprocessed prior usage. Because <code>CBASS</code> clusters both observations and variables, here centering is done by subtracting away the global mean of our data matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Subtracting global mean before computing the CBASS solution path</span>
Xdat.bi &lt;-<span class="st"> </span>Xdat
Xdat.bi.preprocessed &lt;-<span class="st"> </span>Xdat <span class="op">-</span><span class="st">  </span><span class="kw">mean</span>(Xdat)</code></pre></div>
</div>
<div id="dimension-reduction" class="section level3">
<h3 class="hasAnchor">
<a href="#dimension-reduction" class="anchor"></a>Dimension Reduction</h3>
<p>While not directly addressed by <code>CARP</code> or <code>CBASS</code>, high dimensional measurements can present a challenge for clustering methods. Owing to the “curse of dimensionality”, high dimensional measurements may deliver sub-optimal performance for distance-based methods generally. As such, performing dimensionality reduction before applying <code>CARP</code><br>
may result in more interpretable clusters. We leave the choice of dimensionality reduction to the end-user, but still recommend the reduced feature set be pre-processed as described above.</p>
<p>For the purpose of visualuization, <code>CARP</code> addresses the problem of high dimenstionality by visualizing the principal components of the data by default.</p>
</div>
</div>
<div id="weights" class="section level2">
<h2 class="hasAnchor">
<a href="#weights" class="anchor"></a>Weights</h2>
<p>Weights are arguably one of the most important inputs to both <code>CARP</code> and <code>CBASS</code>. As we can see from the optimization probelms above, weights impart apriori preference concerning which observations (and variables in the case of <code>CBASS</code>) should be fused together. This important feature allows us to incorportate domain knowledge, if available. In the absense of domain knowledge, however, weights can easily be constructed via the data itself.</p>
<p>One might first consider simply using a set of uninformative weights, <span class="math inline">\(w_{l.m} = 1\)</span>. While perhaps not appearent at first, such weight choices can also greatly affect the computation time of both <code>CARP</code> and <code>CBASS</code> (and certainly Convex Clustering). To see this note that in the Convex Clustering problem above the regularization term contains <span class="math inline">\(\binom{n}{2}\)</span> summands, drastically increasing computations as <span class="math inline">\(n\)</span> increases. Computations can be reduced by making the majority of weights zero and greatly reducing the number of summands.</p>
<p>Here we detail <code>clustRviz</code>’s default weight choices, as well as how weights can be constructed manually. By default <code>CARP</code> and <code>CBASS</code> assume no prior domain knowledge and construct distance-based weights via a gaussian kernel:</p>
<p><span class="math display">\[
w_{l,m}  = \exp\{ -\phi \|{\boldsymbol{x}}_l - {\boldsymbol{x}}_m \|^2_2 \}
\]</span> Given a choice of <span class="math inline">\(\phi\)</span> (discussed in more detail below), an initial set of weights can be constructed via <code>DenseWeights</code> function. In the case of presidential speech data for example,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dense.weights &lt;-<span class="st"> </span>clustRviz<span class="op">:::</span><span class="kw"><a href="../reference/DenseWeights.html">DenseWeights</a></span>(<span class="dt">X =</span> Xdat.preprocessed,<span class="dt">phi=</span><span class="fl">1e-3</span>)
<span class="kw">head</span>(dense.weights)
<span class="co">#&gt; [1] 0.9053890 0.9676079 0.5474781 0.8777638 0.8041133 0.9350156</span></code></pre></div>
<p>As the name suggests <code>DenseWeights</code> computes <span class="math inline">\(w_{l,m}\)</span> for all pairs of observations. For the presidents data, with <span class="math inline">\(n=44\)</span> observations, this results in a vector of length <span class="math inline">\(\binom{44}{2} = 956\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(dense.weights)
<span class="co">#&gt; [1] 946</span></code></pre></div>
<p>The weights are returned in lexicographical order, namely <span class="math inline">\({\boldsymbol{w}} = (w_{1,2},w_{1,3},\dots,w_{l,m},\dots,w_{n-1,n} )\)</span> The value of <span class="math inline">\(\phi\)</span> can have a marked effect on the weights.</p>
<div class="figure" style="text-align: center">
<img src="clusRvizDetails_files/figure-html/unnamed-chunk-6-1.png" alt="Dense weights for different choices of phi" width="960"><p class="caption">
Dense weights for different choices of phi
</p>
</div>
<p>The choice of <span class="math inline">\(\phi\)</span> determines variance of the weights. Generally, choices of <span class="math inline">\(\phi\)</span> which result in higher variance weights tend to be more informative. A simple method for finding a reasonable choice of <span class="math inline">\(\phi\)</span> is a basic grid search. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">phi.vec &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span>(<span class="op">-</span><span class="dv">4</span><span class="op">:</span><span class="dv">4</span>)
<span class="kw">sapply</span>(phi.vec,<span class="cf">function</span>(phi){
  <span class="kw">var</span>(clustRviz<span class="op">:::</span><span class="kw"><a href="../reference/DenseWeights.html">DenseWeights</a></span>(<span class="dt">X=</span>Xdat.preprocessed,<span class="dt">phi =</span> phi))
}) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">which.max</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>phi.vec[.]
<span class="co">#&gt; [1] 0.01</span></code></pre></div>
<p>Additionally, <code>DenseWeights</code> allows for the specification of alternative distance measures. Depending on the dataset, alternative metrics to traditional euclidean distance may result in more informative clustering solutions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dense.weights.can &lt;-<span class="st"> </span>clustRviz<span class="op">:::</span><span class="kw"><a href="../reference/DenseWeights.html">DenseWeights</a></span>(<span class="dt">X =</span> Xdat.preprocessed,<span class="dt">phi=</span><span class="fl">1e-5</span>,<span class="dt">method =</span> <span class="st">'canberra'</span>)</code></pre></div>
<div class="figure" style="text-align: center">
<img src="clusRvizDetails_files/figure-html/unnamed-chunk-9-1.png" alt="Dense weights with Canberra distance" width="672"><p class="caption">
Dense weights with Canberra distance
</p>
</div>
<p>Distance-based weights can be made sparse by only fusing together nearest neighbors. For a given observations <span class="math inline">\(l\)</span> we consider its <span class="math inline">\(k\)</span> nearest neighbors <span class="math inline">\(\textrm{ne}_k(l)\)</span>. Given a pair of observations <span class="math inline">\(l,m\)</span>, we set their corresponding weight, <span class="math inline">\(w_{l,m}\)</span>, to zero if either is not amongst the other nearest neighbors. Specifically,</p>
<p><span class="math display">\[
\tilde{w}_{l,m} = w_{l,m} {\boldsymbol{1}}_{\textrm{ne}_k(l)}(m) {\boldsymbol{1}}_{\textrm{ne}_k(m)}(l)
\]</span> where <span class="math inline">\(w_{l,m}\)</span> is our original dense weight values and <span class="math inline">\({\boldsymbol{1}}_{A}(x)\)</span> denotes the indicator function of the set <span class="math inline">\(A\)</span>.</p>
<p>For a specifid value of <span class="math inline">\(k\)</span>, a sparse vector of <span class="math inline">\(k\)</span> nearest neighbor weights can be generated via the <code>SparseWeights</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">k.neighbors &lt;-<span class="st"> </span><span class="dv">5</span>
clustRviz<span class="op">:::</span><span class="kw"><a href="../reference/SparseWeights.html">SparseWeights</a></span>(
  <span class="dt">X=</span>Xdat.preprocessed,
  <span class="dt">dense.weights =</span> dense.weights,
  <span class="dt">k =</span> k.neighbors) -&gt;<span class="st"> </span>sparse.weights</code></pre></div>
<p>In the case of <span class="math inline">\(k=\)</span> 5 above, the number of non-zero weight values (and hence the number of summands in our original objective) has been reduced from <span class="math inline">\(\binom{44}{2} = 956\)</span> to</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(sparse.weights<span class="op">!=</span><span class="dv">0</span>)
<span class="co">#&gt; [1] 144</span></code></pre></div>
<p>Computationally, it is tempting to set <span class="math inline">\(k\)</span> small and ensure fast compuatation. Setting <span class="math inline">\(k\)</span> too small, however, can potentially prevent observations from fusing, regardless of the amount of regularization. In order to verify that our sparse set of weights allows for the eventual fusion of all observations we can examine its graphical representation. The function <code>PlotWeightGraph</code> displays the fusion graph of our observations induced by the support of our weight set. The fusion graph displays each observation as a vertex, and connects two observation with an edge if their corresponding weight is non-zero. Such connections between observations indicate their ability fuse into a common cluster, given large enough regularization.</p>
<p>Below we consider the extreme case of <span class="math inline">\(k=1\)</span>, which while computationally fast presents an immediate difficulty.</p>
<p>Examining the graph above, we note that the number of connected components is strictly greater than one. As such, regardless of the number of <code>CARP</code> iteratations (and the associated regularization increases) it will not be possible fuse all observations into a single cluster. Such extreme weight choices should typically be avoided as they not only hinder the agglomorative nature of <code>CARP</code> and <code>CBASS</code>, but also lead to biased and less interpretable solution paths.</p>
<p>At the other extreme, large values of <span class="math inline">\(k\)</span> again result in long computation time and bring little to no improvement on the resulting solution sequence; an example of such an overly dense graph can be seen below.</p>
<p>In order to provide a reasonable choice regarding weight sparsity, the function <code>MinKNN</code> may be used to find a balance between computational efficiency and poor clustering performance. <code>MinKNN</code> takes as its arguement an initial set of dense weights and returns the smallest <span class="math inline">\(k\)</span> such the graph induced by the support of the resulting set of sparse weights contains exactly one connected component. For our current vector of weights we have:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clustRviz<span class="op">:::</span><span class="kw"><a href="../reference/MinKNN.html">MinKNN</a></span>(
  <span class="dt">X =</span> Xdat.preprocessed,
  <span class="dt">dense.weights =</span> dense.weights
) -&gt;<span class="st"> </span>k.min
k.min
<span class="co">#&gt; [1] 4</span></code></pre></div>
<p>Using the <code>k.min</code> value above we may compute the corresponding sparse weight vector and view its resulting graph below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clustRviz<span class="op">:::</span><span class="kw"><a href="../reference/SparseWeights.html">SparseWeights</a></span>(
  <span class="dt">X =</span> Xdat.preprocessed,
  <span class="dt">dense.weights =</span> dense.weights,
  <span class="dt">k =</span> k.min
) -&gt;<span class="st"> </span>sparse.weights</code></pre></div>
<p>We can see that the resulting graph offers a compromise between the two extremes. By default both <code>CARP</code> and <code>CBASS</code> use the value returned by <code>MinKNN</code> to produce sparse sets of weights. While slightly larger values of <span class="math inline">\(k\)</span> can be used, it is not recommended to pass below this threshold for the reasons stated above.</p>
</div>
</div>
<div id="fitting" class="section level1">
<h1 class="hasAnchor">
<a href="#fitting" class="anchor"></a>Fitting</h1>
<p><code>clustRviz</code> aims to make it easy to compute the CARP and CBASS solution paths, and to quickly begin exploring the results. To this end, many reasonable choices regarding both preprocessing and inputs disucussed above are made by default, allowing for solution path to be computed from the raw data alone. In the case of CARP, for example, we may fit the compute the solution path for the presidents data via the <code>CARP</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">carp.fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/CARP.html">CARP</a></span>(<span class="dt">X=</span>Xdat)</code></pre></div>
<p>Once completed, we can examine a brief summary of the fitted object</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">carp.fit
<span class="co">#&gt; CARP Fit Summary</span>
<span class="co">#&gt; ====================</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Algorithm:  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Available Visualizations:</span>
<span class="co">#&gt;  - Static Dendrogram:          TRUE </span>
<span class="co">#&gt;  - Static Cluster Path:        TRUE </span>
<span class="co">#&gt;  - Interactive Visualization:  TRUE </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Observations:  44 </span>
<span class="co">#&gt; Number of Variables:     75 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Pre-processing options:</span>
<span class="co">#&gt;  - Columnwise centering:  TRUE </span>
<span class="co">#&gt;  - Columnwise scaling:    FALSE </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; RBF Kernel Weights:</span>
<span class="co">#&gt;  - phi =  0.01 </span>
<span class="co">#&gt;  - K   =  4 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Raw Data:</span>
<span class="co">#&gt;                     amount appropri  british     cent commerci</span>
<span class="co">#&gt; Abraham Lincoln   3.433987 2.397895 1.791759 2.564949 2.708050</span>
<span class="co">#&gt; Andrew Jackson    4.248495 4.663439 2.995732 1.945910 3.828641</span>
<span class="co">#&gt; Andrew Johnson    4.025352 3.091042 2.833213 3.332205 2.772589</span>
<span class="co">#&gt; Barack Obama      1.386294 0.000000 0.000000 1.386294 0.000000</span>
<span class="co">#&gt; Benjamin Harrison 4.060443 4.174387 2.302585 4.304065 3.663562</span></code></pre></div>
<p>The output above displays characteristics of our data, such as sample size and number of variables, and also gives a preview of the raw input. Additionally, the summary provides information regarding both data pre-processing and weight computations. From the above we see that <code>CARP</code> has by default: (i) centered our data, (ii) computed distance-based weights using a gaussian kernel with <span class="math inline">\(\phi=.01\)</span>, and (iii) created a sparse set of weights using <span class="math inline">\(k=4\)</span> nearest neighbors. Finally, the summary also provides information about the algorithm, here CARP-VIZ, as well as the available visualizations.</p>
<p>While <code>CARP</code>’s default choices work well in most scenarios, customized inputs can also be provided via the <code>control</code> arguement. For example, choices regrarding preprocessing and weight computations discussed above can quickly be incorporated:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/CARP.html">CARP</a></span>(
  <span class="dt">X=</span>Xdat,
  <span class="dt">control =</span> <span class="kw">list</span>(
    <span class="dt">X.center=</span><span class="ot">TRUE</span>,
    <span class="dt">X.scale=</span><span class="ot">TRUE</span>,
    <span class="dt">phi =</span> <span class="fl">1e-5</span>,
    <span class="dt">weight.dist =</span> <span class="st">'canberra'</span>,
    <span class="dt">k =</span> <span class="dv">5</span>
  )
) -&gt;<span class="st"> </span>carp.fit.custom</code></pre></div>
<p>Indeed, in the case where strong apriori information concerning clusters is available, distance-based weight computations may be avoided altogether and user-specified weights given directly via the <code>weights</code> in the control list; see <code><a href="../reference/carp.control.html">?carp.control</a></code> for details.</p>
<p><code>CBASS</code> solutions can be fit in a similar manner:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/CBASS.html">CBASS</a></span>(<span class="dt">X=</span>Xdat) -&gt;<span class="st"> </span>cbass.fit</code></pre></div>
<p>And display its output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cbass.fit
<span class="co">#&gt; CBASS Fit Summary</span>
<span class="co">#&gt; ====================</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Algorithm:  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Available Visualizations:</span>
<span class="co">#&gt;  - Static Dendrogram:    TRUE </span>
<span class="co">#&gt;  - Static Heatmap:       TRUE </span>
<span class="co">#&gt;  - Interactive Heatmap:  TRUE </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Observations:  44 </span>
<span class="co">#&gt; Number of Variables:     75 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Pre-processing options:</span>
<span class="co">#&gt;  - Global centering:  TRUE </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Observation RBF Kernel Weights:</span>
<span class="co">#&gt;  - phi =  0 </span>
<span class="co">#&gt;  - K   =  4 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Variable RBF Kernel Weights:</span>
<span class="co">#&gt;  - phi =  0 </span>
<span class="co">#&gt;  - K   =  2 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Raw Data:</span>
<span class="co">#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]</span>
<span class="co">#&gt; [1,] 3.433987 2.397895 1.791759 2.564949 2.708050</span>
<span class="co">#&gt; [2,] 4.248495 4.663439 2.995732 1.945910 3.828641</span>
<span class="co">#&gt; [3,] 4.025352 3.091042 2.833213 3.332205 2.772589</span>
<span class="co">#&gt; [4,] 1.386294 0.000000 0.000000 1.386294 0.000000</span>
<span class="co">#&gt; [5,] 4.060443 4.174387 2.302585 4.304065 3.663562</span></code></pre></div>
<div id="algorithm-types" class="section level2">
<h2 class="hasAnchor">
<a href="#algorithm-types" class="anchor"></a>Algorithm Types</h2>
<p>Another input into the fitting procedure is the algorithm type. By default both <code>CARP</code> and <code>CBASS</code> use <code>VIZ</code>-type extentions of Algorithmic Regularization to ensure dendrogram existence. However, for larger datasets (<span class="math inline">\(n.obs &gt; 300\)</span>) this default procedure can be computationally burdensome. To ameloriate this difficulty, traditional Algorithmic Regularization can be used, and it computation time controlled via the multiplicitive step-size parameter, <span class="math inline">\(t &gt; 1\)</span>.</p>
<p>In the example below we again fit the presidental speech dataset using the <code>carp</code> algorithim with step size <span class="math inline">\(t=1.1\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/CARP.html">CARP</a></span>(
  <span class="dt">X=</span>Xdat,
  <span class="dt">control=</span>
    <span class="kw">list</span>(
      <span class="dt">alg.type=</span><span class="st">'carp'</span>,
      <span class="dt">t=</span><span class="fl">1.1</span>
    )
) -&gt;<span class="st"> </span>carp.fit.t
carp.fit.t
<span class="co">#&gt; CARP Fit Summary</span>
<span class="co">#&gt; ====================</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Algorithm:  CARP (t = 1.1) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Available Visualizations:</span>
<span class="co">#&gt;  - Static Dendrogram:          TRUE </span>
<span class="co">#&gt;  - Static Cluster Path:        TRUE </span>
<span class="co">#&gt;  - Interactive Visualization:  TRUE </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Observations:  44 </span>
<span class="co">#&gt; Number of Variables:     75 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Pre-processing options:</span>
<span class="co">#&gt;  - Columnwise centering:  TRUE </span>
<span class="co">#&gt;  - Columnwise scaling:    FALSE </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; RBF Kernel Weights:</span>
<span class="co">#&gt;  - phi =  0.01 </span>
<span class="co">#&gt;  - K   =  4 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Raw Data:</span>
<span class="co">#&gt;                     amount appropri  british     cent commerci</span>
<span class="co">#&gt; Abraham Lincoln   3.433987 2.397895 1.791759 2.564949 2.708050</span>
<span class="co">#&gt; Andrew Jackson    4.248495 4.663439 2.995732 1.945910 3.828641</span>
<span class="co">#&gt; Andrew Johnson    4.025352 3.091042 2.833213 3.332205 2.772589</span>
<span class="co">#&gt; Barack Obama      1.386294 0.000000 0.000000 1.386294 0.000000</span>
<span class="co">#&gt; Benjamin Harrison 4.060443 4.174387 2.302585 4.304065 3.663562</span></code></pre></div>
<p><code>CBASS</code> also allows for the use of pure Algorithmic Regularization based approaches in a similar manner. Passing <code>alg.type=cbass</code> along with an associated <span class="math inline">\(t\)</span> value, will produce much faster computations for larger datasets.</p>
<p>By default both <code>CARP</code> and <code>CBASS</code> perform <span class="math inline">\(l_2\)</span> regularization between observation pairs to encourage fusions, and hence cluster formation. <span class="math inline">\(l_1\)</span> regularization may also be used again by passing the algorithm string to the control arguement; see <code>alg.type</code> in <code><a href="../reference/carp.control.html">?carp.control</a></code> and <code><a href="../reference/cbass.control.html">?cbass.control</a></code> for details.</p>
</div>
</div>
<div id="solutions" class="section level1">
<h1 class="hasAnchor">
<a href="#solutions" class="anchor"></a>Solutions</h1>
<p>Once fit, the clustering solution of both CARP and CBASS may be examined via the <code>clustering</code> function. Using our <code>carp.fit</code> object from above, we can extract the solution along the path which gives <span class="math inline">\(k=2\)</span> clusters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">carp.clustering &lt;-<span class="st"> </span><span class="kw"><a href="../reference/clustering.html">clustering</a></span>(carp.fit,<span class="dt">k =</span> <span class="dv">2</span>)</code></pre></div>
<p>Once extracted we may examine the clustering assignment. In the table below we see of count of the cluster membership. Additionally we consider the cluster assignment in relation to our original weight graph. We can see that the cluster membership respect our original weights.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(carp.clustering<span class="op">$</span>clustering.assignment)
<span class="co">#&gt; </span>
<span class="co">#&gt; cl1 cl2 </span>
<span class="co">#&gt;  30  14</span></code></pre></div>
<p>Additionally, we can extract the cluster means associated with <span class="math inline">\(k=2\)</span> solution. The object <code>cluster.means</code> below gives the CARP iterate <span class="math inline">\({\boldsymbol{U}}^{(k)}\)</span> along the path. We note that the columns of the respective clusters have fused together as desired.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(carp.clustering<span class="op">$</span>cluster.means)
<span class="co">#&gt;           cl1       cl2</span>
<span class="co">#&gt; [1,] 3.247043 1.8627224</span>
<span class="co">#&gt; [2,] 3.226682 2.0425014</span>
<span class="co">#&gt; [3,] 2.312455 0.5157932</span>
<span class="co">#&gt; [4,] 2.055121 0.7925161</span>
<span class="co">#&gt; [5,] 2.743924 0.9780746</span>
<span class="co">#&gt; [6,] 2.380273 0.1980421</span></code></pre></div>
<p>Along with specifying the number of clusters <span class="math inline">\(k\)</span>, we may also specify the percent of regulariziation. In the example below, we extract the clustering solution at <span class="math inline">\(25\)</span>% along the regularization path.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">carp.clustering &lt;-<span class="st"> </span><span class="kw"><a href="../reference/clustering.html">clustering</a></span>(carp.fit,<span class="dt">percent =</span> <span class="fl">.25</span>)</code></pre></div>
<p>Simiarly to CARP objects, CBASS clustering solutions may also be extracted via the <code>clustering</code> function. The desired clustering solution is returned by specifying either the number of observation clusters (<code>k.obs</code>), the number of variable clusters (<code>k.var</code>), or the percent of regularization (<code>percent</code>). In any case, <code>clustering</code> returns the observation and variable clustering assignments, as well as the matrix of cluster means. In the example below we extract the biclustering solution at the level of <span class="math inline">\(85\)</span>% regularization.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cbass.clustering &lt;-<span class="st"> </span><span class="kw"><a href="../reference/clustering.html">clustering</a></span>(cbass.fit,<span class="dt">percent =</span> <span class="fl">.85</span>)
<span class="co"># observation clusters</span>
<span class="kw">table</span>(cbass.clustering<span class="op">$</span>clustering.assignment.obs)
<span class="co">#&gt; </span>
<span class="co">#&gt; cl1 cl2 cl3 </span>
<span class="co">#&gt;  29  14   1</span>
<span class="co"># variable clusters</span>
<span class="kw">table</span>(cbass.clustering<span class="op">$</span>clustering.assignment.var)
<span class="co">#&gt; </span>
<span class="co">#&gt; cl1 </span>
<span class="co">#&gt;  75</span>
<span class="co"># mean matrix</span>
cbass.clustering<span class="op">$</span>cluster.mean.matrix[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]
<span class="co">#&gt;          Abraham Lincoln Andrew Jackson Andrew Johnson Barack Obama</span>
<span class="co">#&gt; amount        -0.1969111     -0.1969111     -0.1969111    0.4546688</span>
<span class="co">#&gt; appropri      -0.1969111     -0.1969111     -0.1969111    0.4546688</span>
<span class="co">#&gt; british       -0.1969111     -0.1969111     -0.1969111    0.4546688</span>
<span class="co">#&gt; cent          -0.1969111     -0.1969111     -0.1969111    0.4546688</span>
<span class="co">#&gt; commerci      -0.1969111     -0.1969111     -0.1969111    0.4546688</span>
<span class="co">#&gt;          Benjamin Harrison</span>
<span class="co">#&gt; amount          -0.1969111</span>
<span class="co">#&gt; appropri        -0.1969111</span>
<span class="co">#&gt; british         -0.1969111</span>
<span class="co">#&gt; cent            -0.1969111</span>
<span class="co">#&gt; commerci        -0.1969111</span></code></pre></div>
</div>
<div id="visualizations" class="section level1">
<h1 class="hasAnchor">
<a href="#visualizations" class="anchor"></a>Visualizations</h1>
<p>An important feature of both CARP and CBASS fits is the ability to visualize an entire path of solutions. Unlike traditional clustering methods, CARP and CBASS allow for dynamic visualization of cluster formation, giving a more wholistic view of the underlying data.</p>
<p>In this section we examine both static and dynamic visualizations for CARP and CBASS.</p>
<div id="static" class="section level2">
<h2 class="hasAnchor">
<a href="#static" class="anchor"></a>Static</h2>
<p>Static visualizations allow the user to view snapshots along the cluster solution path. In the plot below the first two principal components of the original observations (US presidents) are plotted (black dots) along with the CARP solution path (red curves). Following along the CARP solution path, we can watch<br>
the fusions between observations as regulaization increases. To obtain a snapshot we again specify the percent of regularization.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(carp.fit,<span class="dt">type =</span> <span class="st">'path'</span>,<span class="dt">percent=</span>.<span class="dv">5</span>)</code></pre></div>
<p><img src="clusRvizDetails_files/figure-html/unnamed-chunk-25-1.png" width="480" style="display: block; margin: auto;"></p>
<p>Owing to the CARP-VIZ algorithm, we are also ensured a dendrogram representation for the resulting path. In the figure below we display the dendrogram of CARP-VIZ:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(carp.fit,<span class="dt">type =</span> <span class="st">'dendrogram'</span>)</code></pre></div>
<p><img src="clusRvizDetails_files/figure-html/unnamed-chunk-26-1.png" width="480" style="display: block; margin: auto;"></p>
<p>Additional static visualization are available for CBASS objects, allowing both static heatmaps and dendrograms for observations and variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(cbass.fit,<span class="dt">type=</span><span class="st">'var.dendrogram'</span>)</code></pre></div>
</div>
<div id="dynamic" class="section level2">
<h2 class="hasAnchor">
<a href="#dynamic" class="anchor"></a>Dynamic</h2>
<p>The dynamic visualization of both CARP and CBASS give a wholistic view of cluster formation. Via the use of Shiny applications, dynamic displays of dendrograms, clustering solution paths, and biclustering heatmaps may be easily obtained.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(carp.fit,<span class="dt">type=</span><span class="st">'interactive'</span>)</code></pre></div>
<iframe src="https://clustrviz.shinyapps.io/PathShiny/" width="100%" height="850px">
</iframe>
<p>Also for CBASS:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(cbass.fit,<span class="dt">type=</span><span class="st">'interactive'</span>)</code></pre></div>
</div>
<div id="saving" class="section level2">
<h2 class="hasAnchor">
<a href="#saving" class="anchor"></a>Saving</h2>
<p><code>clustRviz</code> allows for visualizations, both static and dynamic, to be easily saved for use in presentations and publications. Static snapshots of the clustering solution paths may be saved via the <code>saveviz</code> function. Similar to plotting a CARP object, the percent of regularization is sufficient to obtain a visualization along the path:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/saveviz.html">saveviz</a></span>(
  carp.fit,
  <span class="dt">file.name =</span> <span class="st">'carp_path_static.png'</span>,
  <span class="dt">plot.type =</span> <span class="st">'path'</span>,
  <span class="dt">image.type =</span> <span class="st">'static'</span>,
  <span class="dt">percent=</span>.<span class="dv">5</span>
)</code></pre></div>
<p><code>saveviz</code> allows the user to specify both the the <code>plot.type</code> (cluster path or dendgram) and the <code>image.type</code> (static or dynamic). In the static example above, a <code>.png</code> file of the CARP solution path at <span class="math inline">\(50\)</span>% regularization is outputed. In a similar manner, dendrograms may also be easily saved:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/saveviz.html">saveviz</a></span>(
  carp.fit,
  <span class="dt">file.name =</span> <span class="st">'carp_dend_static.png'</span>,
  <span class="dt">plot.type =</span> <span class="st">'dendrogram'</span>,
  <span class="dt">image.type =</span> <span class="st">'static'</span>,
  <span class="dt">percent=</span>.<span class="dv">5</span>
)</code></pre></div>
<p>Dynamic visualizations can also be saved for viewing outside of Shiny applications. In the case of dynamic visuals, <code>saveviz</code> will output a <code>.gif</code> demonstrating cluster formation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/saveviz.html">saveviz</a></span>(
  carp.fit,
  <span class="dt">file.name =</span> <span class="st">'path_dyn.gif'</span>,
  <span class="dt">plot.type =</span> <span class="st">'path'</span>,
  <span class="dt">image.type =</span> <span class="st">'dynamic'</span>
)</code></pre></div>
<p><code>saveviz</code> may be used for CBASS objects as well, outputing dendrograms for observation or variables, as well as heatmaps. In the example below we save a <code>.gif</code> biclustering heatmap.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/saveviz.html">saveviz</a></span>(
  cbass.fit,
  <span class="dt">file.name =</span> <span class="st">'cbass_heat_dyn.gif'</span>,
  <span class="dt">plot.type =</span> <span class="st">'heatmap'</span>,
  <span class="dt">image.type =</span> <span class="st">'dynamic'</span>
)</code></pre></div>
</div>
</div>
<div id="discussion" class="section level1">
<h1 class="hasAnchor">
<a href="#discussion" class="anchor"></a>Discussion</h1>
<p><code>clustRviz</code> provides a integrated framework for fitting and visualizing the CARP and CBASS solution paths. <code>clustRviz</code> delivers fast computation relative to traditional Convex Clustering solution techniques, and brings traditional and modern clustering visualization techniques together in a unified framework.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-boyd2011distributed">
<p>Boyd, Stephen, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein. 2011. “Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.” <em>Foundations and Trends in Machine Learning</em> 3 (1). Now Publishers Inc.: 1–122.</p>
</div>
<div id="ref-chi2015splitting">
<p>Chi, Eric C, and Kenneth Lange. 2015. “Splitting Methods for Convex Clustering.” <em>Journal of Computational and Graphical Statistics</em> 24 (4). Taylor &amp; Francis: 994–1013.</p>
</div>
<div id="ref-hocking2011clusterpath">
<p>Hocking, Toby Dylan, Armand Joulin, Francis Bach, and Jean-Philippe Vert. 2011. “Clusterpath an Algorithm for Clustering Using Convex Fusion Penalties.” In <em>28th International Conference on Machine Learning</em>, 1.</p>
</div>
<div id="ref-hu2016admm">
<p>Hu, Yue, Eric C Chi, and Genevera I Allen. 2016. “ADMM Algorithmic Regularization Paths for Sparse Statistical Machine Learning.” In <em>Splitting Methods in Communication, Imaging, Science, and Engineering</em>, 433–59. Springer.</p>
</div>
<div id="ref-tan2015statistical">
<p>Tan, Kean Ming, and Daniela Witten. 2015. “Statistical Properties of Convex Clustering.” <em>Electronic Journal of Statistics</em> 9 (2). NIH Public Access: 2324.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#background">Background</a></li>
      <li>
<a href="#preprocessing-and-inputs">Preprocessing and Inputs</a><ul class="nav nav-pills nav-stacked">
<li><a href="#preprocessing">Preprocessing</a></li>
      <li><a href="#weights">Weights</a></li>
      </ul>
</li>
      <li>
<a href="#fitting">Fitting</a><ul class="nav nav-pills nav-stacked">
<li><a href="#algorithm-types">Algorithm Types</a></li>
      </ul>
</li>
      <li><a href="#solutions">Solutions</a></li>
      <li>
<a href="#visualizations">Visualizations</a><ul class="nav nav-pills nav-stacked">
<li><a href="#static">Static</a></li>
      <li><a href="#dynamic">Dynamic</a></li>
      <li><a href="#saving">Saving</a></li>
      </ul>
</li>
      <li><a href="#discussion">Discussion</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by John Nagorski.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
