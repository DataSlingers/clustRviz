---
title: "clustRviz Details"
author: "John Nagorski"
date: "`r Sys.Date()`"
bibliography: vignettes.bib
output: 
  rmarkdown::html_vignette:
    css: style.css
vignette: >
  %\VignetteIndexEntry{clustRviz Details}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval=TRUE,
  message = FALSE
)
```

\renewcommand{\vec}[1]{\boldsymbol{#1}}

# Introduction

The `clustRviz` package intends to make fitting and visualizing CARP and CBASS
solution paths an easy process. In the [Getting Started](Getting_Started.html)
vignettee we provide a quick start guide for basic usage, fitting,
and plotting. In this vignette, we build on the basics and provide a more
detailed explanation for the variety of options available in `clustRviz`.

# Background

The starting point for CARP is the Convex Clustering
[@Hocking:2011; @Chi:2015; @Tan:2015] problem:

$$
\underset{\vec U}{\textrm{minimize}} \;\;
\frac{1}{2} \| \vec X - \vec U \|_F^2 + 
\lambda \sum_{ l < m} 
w_{l,m} \| \vec u_l - \vec u_m \|_2
$$

where $\vec X$ is an $p \times n$ input data matrix, consisting of $p$ measurements on $n$ subjects,
$\lambda > 0$ a regularization parameter, and
$w_{l,m}>0$ a weight for each pair of observations; here $\| . \|_F$ and $\| . \|_2$ denote
the Frobenius norm and $\ell_2$ norm, respectively.

Briefly, Convex Clustering seeks to find and estimate,$\hat{\vec{U}} \in \mathbb{R}^{p\times n}$, such
that it is faithful to the original data (Frobenius norm loss term) while
also encouraging fusions among observations
($\ell_2$ regularization between columns of $\vec U$, denoted $u_l$).
At small values of regularization, $\lambda \approx 0$, Convex Clustering
returns estimates similar to the original data with little or no fusion among
observations. As regularization increases, more fusions occur and Convex Clustering
returns estimates such that $\| \hat{\vec{u}}_l - \hat{\vec{u}}_m \| = 0$. When
such fusions occur we say that observations $l$ and $m$ belong to the same cluster.
Taken to the extreme, sufficiently large values of $\lambda$ result in all
observations belonging to the same cluster.

When fitting for multiple values of $\lambda$ Convex Clustering results
in a continious solution path of clustering solutions.
One solution method for the problem above is via the alternatving
direction method of multipliers (ADMM) [@Boyd:2011].
For a given $\lambda$, Convex Clustering can be solved by iteratively applying ADMM updates until convergence [@Chi:2015].
However in order to obtain a full path of clustering solutions, this method
must be employed for multiple $\lambda_k$ which is computationally expensive.

To address the computational burden of Convex Clustering,
we utilize the framework of Algorithmic Regularization Paths [@Hu:2016]
to develop efficient methods for approximating the Convex
Clustering and Biclustering solution paths: Convex Clustering via
Algorithmic Regularization Paths (CARP) and Convex Biclustering via
Algorthmic Regularization with Small Steps (CBASS), respectively.
Rather than fully solving the Convex Clustering optimization problem at each $\lambda_k$,
we instead perform single updates combined with gradual increases in
regularization at each step. As regularization increases with
each iteration, the column differences of the iterates, $\| \vec{u}^{(k)}_l - \vec{u}^{(k)}_m \|$,
eventally become $0$ for all $l,m$.
In contrast to traditional iterative solution techniques, we instead
employ the iterates themselves as approximations for the true solution path.
Remarkably, this approximation not only works well empirically, but
can be shown theoretically to well approximate the true Convex
Clustering solution path.

# Preprocessing and Inputs

While the `CARP` and `CBASS` functions provides several reasonable default choices for weights, algorithms, etc, it
is important to know their details if one wishes to compute more customized clustering choices.
Here we examine several of the inputs to `CARP` and `CBASS`, as well as their preprocessing technqiues

Here we use a dataset of presidential speechs obtained from
[The American Presidency Project](http://www.presidency.ucsb.edu/index_docs.php)
to illustrate the use of `clustRviz`.
The presidential speech data set contains the top 75 most variable
log-transformed word counts of each US president, aggregated over several
speeches. Additional text processing such as removing stop words and
stemming have been done via the `tm` package.

Let's begin by loading our package and the dataset:

```{r}
library(clustRviz)
data("presidential_speech")
Xdat <- presidential_speech
row_labels <- rownames(Xdat)
col_labels <- colnames(Xdat)
Xdat[1:5,1:5]
head(row_labels)
head(col_labels)
```

## Preprocessing 

### Normalization

An important first choice before clustering is whether to center and scale our observations.
Centering is typically appropriate, and is done by default for CARP and CBASS.
The choice of scaling is left to the user discression, but should typically be applied 
if measurements are a vastly different scales.
In the case of the presidental speech dataset, all variables are of the same type and 
so we do not scale our data matrix.

```{r}
# Centering data before computing the CARP solution path
Xdat.preprocessed <- scale(Xdat, center=TRUE, scale=FALSE)
```

In the `CARP` function this preprocessing is done via the `X.center` and `X.scale`
arguements. If the data is pre-processed outside of `CARP`, as is the case here,
these options may be set to `FALSE`; by default, `CARP` with center but not
scale an inputted data matrix.

Both `CARP` and `CBASS` (below) admit several options for computing the (bi)clustering 
solution path. While we will encounter many options along the way, see the relevant
documentation for full details.

Similarly, the `CBASS` function also requires that data preprocessed prior usage.
Because `CBASS` clusters both observations and variables, here centering is done
by subtracting away the global mean of our data matrix.

```{r}
# Subtracting global mean before computing the CBASS solution path
Xdat.bi <- Xdat
Xdat.bi.preprocessed <- Xdat -  mean(Xdat)
```

### Dimension Reduction

While not directly addressed by `CARP` or `CBASS`, high dimensional
measurements can present a challenge for clustering methods.
Owing to the "curse of dimensionality", high dimensional measurements 
may deliver sub-optimal performance for distance-based methods generally.
As such, performing dimensionality reduction before applying `CARP`
may result in more interpretable clusters.
We leave the choice of dimensionality reduction to the end-user,
but still recommend the reduced feature set be pre-processed
as described above.

For the purpose of visualuization, `CARP` addresses the problem
of high dimenstionality by visualizing the principal components
of the data by default.

### Weights

The use of a good weight scheme is essential to getting reasonable clustering
results from convex clustering (`CARP`) and convex biclustering (`CBASS`). The
`clustRviz` package provides a useful data-driven default weight scheme as well
as allowing users to supply their own weights. Clustering weights are discussed
in much more detail in the [`clustRviz` weights vignette](ClustRVizWeights.html).

# Fitting

`clustRviz` aims to make it easy to compute the CARP and CBASS solution paths, and
to quickly begin exploring the results. To this end, many reasonable choices
regarding both preprocessing and inputs disucussed above are made by default,
allowing for solution path to be computed from the raw data alone.
In the case of CARP, for example, we may fit the compute the solution
path for the presidents data via the `CARP` function:

```{r}
carp_fit <- CARP(X=Xdat)
```

Once completed, we can examine a brief summary of the fitted object:

```{r,message=TRUE}
carp_fit
```

The output above displays characteristics of our data, such as sample size
and number of variables, and also gives a preview of the raw input.
Additionally, the summary provides information regarding both data
pre-processing and weight computations. From the above we see that
`CARP` has by default: (i) centered our data, (ii) computed
distance-based weights using a gaussian kernel with $\phi=.01$, and
(iii) created a sparse set of weights using $k=4$ nearest neighbors.
Finally, the summary also provides information about the algorithm, here 
CARP-VIZ, as well as the available visualizations.

While `CARP`'s default choices work well in most scenarios, the user can change
almost all aspects of the algorithm. For example, if we wish to alter the default
pre-processing and weight choices:

```{r,eval=FALSE}
CARP(Xdat, 
     X.center = TRUE, 
     X.scale = TRUE, 
     weights = sparse_rbf_kernel_weights(phi = 1e-5, 
                                         dist.method = "canberra", 
                                         k = 5))
```

Indeed, in the case where strong *a priori* information concerning clusters is
available, distance-based weight computations may be avoided altogether and
user-specified weights given directly via the `weights` argument. See the
accompaning [weights vignette](ClustRVizWeights.html) for details.

`CBASS` solutions can be fit in a similar manner:

```{r}
cbass_fit <- CBASS(X=Xdat)
```

And display its output:
```{r,message=TRUE}
cbass_fit
```

## Algorithm Types

Another input into the fitting procedure is the
algorithm type. By default both `CARP` and `CBASS` a fixed step-size version
of algorithmic regularization. If the exact dendrogram is of foremost importance, 
the `VIZ`-type back-tracking extentions may be used by passing `back_track = TRUE`. We
note, however, that back-tracking may be computationally burdensome, particularly
for larger data sets. The dendrograms produced by `CARP` and `CBASS` (particularly
with small step-sizes) are sufficient for the vast majority of applications. 

In the example below we again fit the presidental speech dataset using the
default `carp` algorithim with step size $t=1.1$

```{r}
carp_fit_fixed_t <- CARP(Xdat, t = 1.1)
carp_fit_fixed_t
```

By default both `CARP` and `CBASS` perform $\ell_2$ regularization between
observation pairs to encourage fusions, and hence cluster formation. If $\ell_1$
regularization is preferred for whatever reason, the `norm` argument may be set to `1`.

# Solutions

Once fit, the clustering solution of both CARP and CBASS may be examined via
three related "accessor" functions:

- `get_cluster_labels`: to get a named factor vector of cluster labels
- `get_cluster_centroids`: to get a matrix of cluster centroids
- `get_clustered_data`: to get the clustered data matrix
  (data replaced by estimated centroids)

The interface for these functions is essentially the same for `CARP` and `CBASS`
objects, though the exact meaning of "centroids" varies between the problems
(vectors for `CARP` and scalars for `CBASS`). The latter two functions also support
a `refit` flag, which determines whether the convex clustering centroids or the naive
centroids (based only on the convex clustering labels) are returned.

For example, we can extract the clustering labels from our `carp_fit` corresponding
to a $k = 2$ cluster solution:

```{r}
cluster_labels <- get_cluster_labels(carp_fit, k = 2)
head(cluster_labels)
```

We see a rather inbalanced data set (the "pre-WWII" cluster is much larger):

```{r}
table(cluster_labels)
```

Similarly, to get the cluster means, we use the `get_cluster_centroids` function:

```{r}
get_cluster_centroids(carp_fit, k = 2)
```

Since we performed convex clustering here, our centroids are $p$-vectors. By default,
the naive centroids are used; if we prefer the exact convex clustering solution, we
can pass the `refit = FALSE` flag:

```{r}
get_cluster_centroids(carp_fit, k = 2, refit = FALSE)
```

We can instead supply the `percent` argument to specify $\lambda$ (or more precisely,
$\lambda / \lambda_{\text{max}}$) rather than the numer of clusters explicitly. For
example, if we are interested at the clustering solution about $25\%$ of the way
along the regularization path:

```{r}
get_cluster_labels(carp_fit, percent = 0.25)
```

We see that our data is clearly falls into three clusters.

Simiarly to `CARP` objects, `CBASS` clustering solutions may also be extracted via the
three accessor functions. The `CBASS` methods allow one of three parameters to be
used to specify the solution:

- `k.row`: the number of row clusters
- `k.col`: the number of column clusters
- `percent`: the percent of total regularization

Other than this, the behavior of `get_cluster_labels`, and `get_clustered_data`
is roughly the same:

```{r}
# CBASS Cluster Labels for rows (observations = default)
get_cluster_labels(cbass_fit, percent = 0.85, type = "row")

# CBASS Cluster Labels for columns (features)
get_cluster_labels(cbass_fit, percent = 0.85, type = "col")

# CBASS Solution - naive centroids
get_clustered_data(cbass_fit, percent = 0.85)

# CBASS Solution - convex bi-clustering centroids
get_clustered_data(cbass_fit, percent = 0.85, refit = FALSE)
```

The `get_cluster_centroids` function returns a $k_1$-by-$k_2$ matrix, giving
the (scalar) centroids at a solution with $k_1$ row clusters and $k_2$
column clusters:

```{r}
get_cluster_centroids(cbass_fit, percent = 0.85)
```

# Visualizations

An important feature of both CARP and CBASS fits is the ability to visualize
an entire path of solutions. Unlike traditional clustering methods, CARP and CBASS
allow for dynamic visualization of cluster formation, giving a more
wholistic view of the underlying data.

In this section we examine both static and dynamic visualizations for
CARP and CBASS.

## Static

Static visualizations allow the user to view snapshots along the cluster
solution path. In the plot below the first two
principal components of the original observations (US presidents)
are plotted (black dots) along with the CARP solution path (red curves).
Following along the CARP solution path, we can watc
the fusions between observations as regulaization increases.
To obtain a snapshot we again specify the percent of regularization.

```{r,fig.width=5,fig.height=5,fig.align='center'}
plot(carp_fit, type = 'path', percent = .5)
```

The CARP solution path can be used to construct a dendrogram:

```{r,fig.width=5,fig.height=5,fig.align='center'}
plot(carp_fit, type = 'dendrogram')
```

Additional static visualization are available for
CBASS objects, allowing both static heatmaps and
dendrograms for observations and variables.

```{r,echo=TRUE,eval=FALSE}
plot(cbass_fit, type = 'col.dendrogram')
```

## Dynamic

The dynamic visualization of both CARP and CBASS give a wholistic view of cluster formation.
Via the use of Shiny applications, dynamic displays of dendrograms,
clustering solution paths, and biclustering heatmaps may be easily obtained.

```{r,echo=TRUE,eval=FALSE}
plot(carp_fit, type = 'interactive')
```

```{r,echo=FALSE,eval=TRUE,out.width='100%'}
knitr::include_url(url = "https://clustrviz.shinyapps.io/PathShiny/", 
                   height = '850px')
```

Also for CBASS:

```{r,echo=TRUE,eval=FALSE}
plot(cbass_fit, type = 'interactive')
```

## Saving

`clustRviz` allows for visualizations, both static and dynamic, to be easily
saved for use in presentations and publications. Static snapshots of the
clustering solution paths may be saved via the `saveviz` function.
Similar to plotting a CARP object, the percent of regularization 
is sufficient to obtain a visualization along the path:

```{r,echo=TRUE,eval=FALSE}
saveviz(
  carp_fit,
  file.name = 'carp_path_static.png',
  plot.type = 'path',
  image.type = 'static',
  percent=.5
)
```

`saveviz` allows the user to specify both the the `plot.type` (cluster path 
or dendgram) and the `image.type` (static or dynamic). In the static 
example above, a `.png` file of the CARP solution path at $50$\% regularization 
is outputed. In a similar manner, dendrograms may also be easily saved:

```{r,echo=TRUE,eval=FALSE}
saveviz(
  carp_fit,
  file.name = 'carp_dend_static.png',
  plot.type = 'dendrogram',
  image.type = 'static',
  percent=.5
)
```

Dynamic visualizations can also be saved for viewing outside of Shiny applications.
In the case of dynamic visuals, `saveviz` will output a `.gif` demonstrating
cluster formation.

```{r,echo=TRUE,eval=FALSE}
saveviz(
  carp_fit,
  file.name = 'path_dyn.gif',
  plot.type = 'path',
  image.type = 'dynamic'
)
```

`saveviz` may be used for CBASS objects as well, outputing dendrograms
for observation or variables, as well as heatmaps. In the example
below we save a `.gif` biclustering heatmap.

```{r,echo=TRUE,eval=FALSE}
saveviz(
  cbass_fit,
  file.name = 'cbass_heat_dyn.gif',
  plot.type = 'heatmap',
  image.type = 'dynamic'
)
```

# Discussion

`clustRviz` provides a integrated framework for fitting and visualizing the CARP
and CBASS solution paths. `clustRviz` delivers fast computation relative
traditional Convex Clustering solution techniques, and brings traditional and
modern clustering visualization techniques together in a unified framework.

# References
