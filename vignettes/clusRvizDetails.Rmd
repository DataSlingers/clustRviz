---
title: "clustRviz Details"
author: "John Nagorski"
date: "`r Sys.Date()`"
bibliography: vignettes.bib
output: 
  rmarkdown::html_vignette:
    css: style.css
vignette: >
  %\VignetteIndexEntry{clustRviz Details}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval=TRUE,
  message = FALSE
)
```

\renewcommand{\vec}[1]{\boldsymbol{#1}}

# Introduction

The `clustRviz` package intends to make fitting and visualizing CARP and CBASS 
solution paths an easy process. In the [Getting Started](Getting_Started.html) 
vignettee we provide a quick start guide for basic usage, fitting, 
and plotting. In this vignette, we build on the basics and provide a more 
detailed explanation for the variety of options available in `clustRviz`.

# Background

The starting point for CARP is the Convex Clustering 
[@Hocking:2011; @Chi:2015; @Tan:2015] problem :

$$
\underset{\vec U}{\textrm{minimize}} \;\;
\frac{1}{2} \| \vec X - \vec U \|_F^2 + 
\lambda \sum_{ l < m} 
w_{l,m} \| \vec u_l - \vec u_m \|_2
$$

where $\vec X$ is an $p \times n$ input data matrix, consisting of $p$ measurements on $n$ subjects,
$\lambda > 0$ a regularization parameter, and 
$w_{l,m}>0$ a weight for each pair of observations; here $\| . \|_F$ and $\| . \|_2$ denote 
the Frobenius norm and $l_2$ norm, respectively. 

Briefly, Convex Clustering seeks to find and estimate,$\hat{\vec{U}} \in \mathbb{R}^{p\times n}$, such 
that it is faithful to the original data (Frobenius norm loss term) while 
also encouraging fusions among observations 
($l_2$ regularization between columns of $\vec U$, denoted $u_l$).
At small values of regularization, $\lambda \approx 0$, Convex Clustering 
returns estimates similar to the original data with little or no fusion among 
observations. As regularization increases, more fusions occur and Convex Clustering
returns estimates such that $\| \hat{\vec{u}}_l - \hat{\vec{u}}_m \| = 0$. When 
such fusions occur we say that observations $l$ and $m$ belong to the same cluster.
Taken to the extreme, sufficiently large values of $\lambda$ result in all 
observations belonging to the same cluster.

When fitting for multiple values of $\lambda$ Convex Clustering results
in a continious solution path of clustering solutions.
One solution method for the problem above is via the alternatving 
direction method of multipliers (ADMM) [@Boyd:2011].
For a given $\lambda$, Convex Clustering can be solved by iteratively applying ADMM updates until convergence [@Chi:2015].
However in order to obtain a full path of clustering solutions, this method 
must be employed for multiple $\lambda_k$ which is computationally expensive.

To address the computational burden of Convex Clustering,
we utilize the framework of Algorithmic Regularization Paths [@Hu:2016]
to develop efficient methods for approximating the Convex 
Clustering and Biclustering solution paths: Convex Clustering via 
Algorithmic Regularization Paths (CARP) and Convex Biclustering via 
Algorthmic Regularization with Small Steps (CBASS), respectively.
Rather than fully solving the Convex Clustering optimization problem at each $\lambda_k$, 
we instead perform single updates combined with gradual increases in 
regularization at each step. As regularization increases with 
each iteration, the column differences of the iterates, $\| \vec{u}^{(k)}_l - \vec{u}^{(k)}_m \|$,
eventally become $0$ for all $l,m$.
In contrast to traditional iterative solution techniques, we instead 
employ the iterates themselves as approximations 
for the true solution path.
Remarkably, this approximation not only works well empirically, but
can be shown theoretically to well approximate the true Convex 
Clustering solution path.

# Preprocessing and Inputs

While the `CARP` and `CBASS` functions provides several reasonable default choices for weights, algorithms, etc, it
is important to know their details if one wishes to compute more customized clustering choices.
Here we examine several of the inputs to `CARP` and `CBASS`, as well as their preprocessing technqiues 

Here we use a dataset of presidential speechs obtained from 
[The American Presidency Project](http://www.presidency.ucsb.edu/index_docs.php)
to illustrate the use of `clustRviz`.
The presidential speech data set contains the top 75 most variable 
log-transformed word counts of each US president, aggregated over several 
speeches. Additional text processing such as removing stop words and 
stemming have been done via the `tm` package.  

Let's begin by loading our package and the dataset:

```{r}
library(clustRviz)
data("presidential_speech")
Xdat <- presidential_speech
obs.labels <- rownames(Xdat)
var.labels <- colnames(Xdat)
Xdat[1:5,1:5]
head(obs.labels)
head(var.labels)
```

## Preprocessing 

### Normalization
An important first choice before clustering is whether to center and scale our observations.
Centering is typically appropriate, and is done by default for CARP and CBASS.
The choice of scaling is left to the user discression, but should typically be applied 
if measurements are a vastly different scales.
In the case of the presidental speech dataset, all variables are of the same type and 
so we do not scale our data matrix.

```{r}
# Centering data before computing the CARP solution path
Xdat.preprocessed <- scale(Xdat,center=TRUE,scale=FALSE)
```

In the `CARP` function this preprocessing is done via the `X.center` and `X.scale`
arguements.
If the data is pre-processed outside of `CARP`, as is the case here, these options
may be set to `FALSE`; by default, `CARP` with center but not scale an inputted 
data matrix.

Both `CARP` and `CBASS` (below) admit several options for computing the (bi)clustering 
solution path. While we will encounter many options along the way, see the `carp.control` and `cbass.control` 
functions for full details. 

Similarly, the `CBASS` function also requires that data preprocessed prior usage.
Because `CBASS` clusters both observations and variables, here centering is done 
by subtracting away the global mean of our data matrix.

```{r}
# Subtracting global mean before computing the CBASS solution path
Xdat.bi <- Xdat
Xdat.bi.preprocessed <- Xdat -  mean(Xdat)
```

### Dimension Reduction

While not directly addressed by `CARP` or `CBASS`, high dimensional 
measurements can present a challenge for clustering methods.
Owing to the "curse of dimensionality", high dimensional measurements 
may deliver sub-optimal performance for distance-based methods generally.
As such, performing dimensionality reduction before applying `CARP`  
may result in more interpretable clusters.
We leave the choice of dimensionality reduction to the end-user, 
but still recommend the reduced feature set be pre-processed 
as described above.

For the purpose of visualuization, `CARP` addresses the problem 
of high dimenstionality by visualizing the principal components 
of the data by default.

### Weights

The use of a good weight scheme is essential to getting reasonable clustering
results from convex clustering (`CARP`) and convex biclustering (`CBASS`). The 
`clustRviz` package provides a useful data-driven default weight scheme as well
as allowing users to supply their own weights. Clustering weights are discussed
in much more detail in the [`clustRviz` weights vignette](ClustRVizWeights.html).

# Fitting

`clustRviz` aims to make it easy to compute the CARP and CBASS solution paths, and 
to quickly begin exploring the results. To this end, many reasonable choices 
regarding both preprocessing and inputs disucussed above are made by default, 
allowing for solution path to be computed from the raw data alone. 
In the case of CARP, for example, we may fit the compute the solution 
path for the presidents data via the `CARP` function:
```{r}
carp.fit <- CARP(X=Xdat)
```
Once completed, we can examine a brief summary of the fitted object
```{r,message=TRUE}
carp.fit
```
The output above displays characteristics of our data, such as sample size 
and number of variables, and also gives a preview of the raw input. 
Additionally, the summary provides information regarding both data
pre-processing and weight computations. From the above we see that 
`CARP` has by default: (i) centered our data, (ii) computed 
distance-based weights using a gaussian kernel with $\phi=.01$, and 
(iii) created a sparse set of weights using $k=4$ nearest neighbors.
Finally, the summary also provides information about the algorithm, here 
CARP-VIZ, as well as the available visualizations.

While `CARP`'s default choices work well in most scenarios, customized inputs 
can also be provided via the `control` arguement. For example, choices 
regrarding preprocessing and weight computations discussed above can quickly be incorporated:
```{r,eval=FALSE}
CARP(
  X=Xdat,
  control = list(
    X.center=TRUE,
    X.scale=TRUE,
    phi = 1e-5,
    weight.dist = 'canberra',
    k = 5
  )
) -> carp.fit.custom
```
Indeed, in the case where strong apriori information concerning clusters is 
available, distance-based weight computations may be avoided altogether and 
user-specified weights given directly via the `weights` in the control list;
see `?carp.control` for details.

`CBASS` solutions can be fit in a similar manner:

```{r}
CBASS(X=Xdat) -> cbass.fit
```

And display its output:
```{r,message=TRUE}
cbass.fit
```

## Algorithm Types

Another input into the fitting procedure is the 
algorithm type. By default both `CARP` and `CBASS` use `VIZ`-type 
extentions of Algorithmic Regularization to ensure dendrogram existence. 
However, for larger datasets ($n.obs > 300$) this default procedure can 
be computationally burdensome. To ameloriate this difficulty, traditional 
Algorithmic Regularization can be used, and it computation time controlled 
via the multiplicitive step-size parameter, $t > 1$.

In the example below we again fit the presidental speech dataset using the 
`carp` algorithim with step size $t=1.1$

```{r}
CARP(
  X=Xdat,
  control=
    list(
      alg.type='carp',
      t=1.1
    )
) -> carp.fit.t
carp.fit.t
```

`CBASS` also allows for the use of pure Algorithmic Regularization 
based approaches in a similar manner. Passing `alg.type=cbass` along 
with an associated $t$ value, will produce much faster computations for 
larger datasets.

By default both `CARP` and `CBASS` perform $l_2$ regularization between 
observation pairs to encourage fusions, and hence cluster formation. $l_1$
regularization may also be used again by passing the algorithm string 
to the control arguement; see `alg.type` in `?carp.control` and `?cbass.control`
for details.

# Solutions

Once fit, the clustering solution of both CARP and CBASS may be examined 
via the `clustering` function.
Using our `carp.fit` object from above, we can extract the solution along 
the path which gives $k=2$ clusters.

```{r}
carp.clustering <- clustering(carp.fit,k = 2)
```

Once extracted we may examine the clustering assignment. In the table 
below we see of count of the cluster membership. Additionally 
we consider the cluster assignment in relation to our original weight
graph. We can see that the cluster membership respect our original
weights.
```{r}
table(carp.clustering$clustering.assignment)
```

Additionally, we can extract the cluster means associated with $k=2$ solution. The object `cluster.means`
below gives the CARP iterate $\vec U^{(k)}$ along the path. We note that the columns 
of the respective clusters have fused together as desired.
```{r}
head(carp.clustering$cluster.means)
```
Along with specifying the number of clusters $k$, we may also specify the percent of 
regulariziation. In the example below, we extract the clustering solution at $25$\% 
along the regularization path.

```{r}
carp.clustering <- clustering(carp.fit,percent = .25)
```

Simiarly to CARP objects, CBASS clustering solutions may also be extracted via the 
`clustering` function.
The desired clustering solution is returned by
specifying either the number of observation clusters (`k.obs`), 
the number of variable clusters (`k.var`), or the percent of 
regularization (`percent`). In any case, `clustering` returns 
the observation and variable clustering assignments, as well as
the matrix of cluster means.
In the example below we extract the biclustering solution
at the level of $85$\% regularization.

```{r,eval=TRUE}
cbass.clustering <- clustering(cbass.fit,percent = .85)
# observation clusters
table(cbass.clustering$clustering.assignment.obs)
# variable clusters
table(cbass.clustering$clustering.assignment.var)
# mean matrix
cbass.clustering$cluster.mean.matrix[1:5,1:5]
```

# Visualizations

An important feature of both CARP and CBASS fits is the ability to visualize 
an entire path of solutions. Unlike traditional clustering methods, CARP and CBASS
allow for dynamic visualization of cluster formation, giving a more 
wholistic view of the underlying data.

In this section we examine both static and dynamic visualizations for 
CARP and CBASS.

## Static

Static visualizations allow the user to view snapshots along the cluster
solution path. In the plot below
the first two 
principal components of the original observations (US presidents) 
are plotted (black dots) along with the CARP solution path (red curves). 
Following along the CARP solution path, we can watch  
the fusions between observations as regulaization increases.
To obtain a snapshot we again specify the percent of regularization.

```{r,fig.width=5,fig.height=5,fig.align='center'}
plot(carp.fit,type = 'path',percent=.5)
```

Owing to the CARP-VIZ algorithm, we are also ensured a 
dendrogram representation for the resulting path. In the 
figure below we display the dendrogram of CARP-VIZ:

```{r,fig.width=5,fig.height=5,fig.align='center'}
plot(carp.fit,type = 'dendrogram')
```

Additional static visualization are available for 
CBASS objects, allowing both static heatmaps and 
dendrograms for observations and variables.

```{r,echo=TRUE,eval=FALSE}
plot(cbass.fit,type='var.dendrogram')
```

## Dynamic

The dynamic visualization of both CARP and CBASS give a wholistic view 
of cluster formation.
Via the use of Shiny applications, dynamic displays of dendrograms, 
clustering solution paths, and biclustering heatmaps may be easily obtained.

```{r,echo=TRUE,eval=FALSE}
plot(carp.fit,type='interactive')
```

```{r,echo=FALSE,eval=TRUE,out.width='100%'}
knitr::include_url(url="https://clustrviz.shinyapps.io/PathShiny/",height='850px')
```

Also for CBASS:

```{r,echo=TRUE,eval=FALSE}
plot(cbass.fit,type='interactive')
```

## Saving

`clustRviz` allows for visualizations, both static and dynamic, to be 
easily saved for use in presentations and publications. 
Static snapshots of the clustering solution paths may be 
saved via the `saveviz` function.
Similar to 
plotting a CARP object, the percent of regularization 
is sufficient to obtain a visualization along the path:

```{r,echo=TRUE,eval=FALSE}
saveviz(
  carp.fit,
  file.name = 'carp_path_static.png',
  plot.type = 'path',
  image.type = 'static',
  percent=.5
)
```

`saveviz` allows the user to specify both the the `plot.type` (cluster path 
or dendgram) and the `image.type` (static or dynamic). In the static 
example above, a `.png` file of the CARP solution path at $50$\% regularization 
is outputed. In a similar manner, dendrograms may also be easily saved:

```{r,echo=TRUE,eval=FALSE}
saveviz(
  carp.fit,
  file.name = 'carp_dend_static.png',
  plot.type = 'dendrogram',
  image.type = 'static',
  percent=.5
)
```

Dynamic visualizations can also be saved for viewing outside of Shiny applications.
In the case of dynamic visuals, `saveviz` will output a `.gif` demonstrating 
cluster formation.

```{r,echo=TRUE,eval=FALSE}
saveviz(
  carp.fit,
  file.name = 'path_dyn.gif',
  plot.type = 'path',
  image.type = 'dynamic'
)
```

`saveviz` may be used for CBASS objects as well, outputing dendrograms 
for observation or variables, as well as heatmaps. In the example 
below we save a `.gif` biclustering heatmap.

```{r,echo=TRUE,eval=FALSE}
saveviz(
  cbass.fit,
  file.name = 'cbass_heat_dyn.gif',
  plot.type = 'heatmap',
  image.type = 'dynamic'
)

```

# Discussion

`clustRviz` provides a integrated framework for fitting and visualizing 
the CARP and CBASS solution paths. 
`clustRviz` delivers fast computation relative to traditional Convex Clustering 
solution techniques, and brings traditional and modern clustering 
visualization techniques together in a unified framework.

# References
